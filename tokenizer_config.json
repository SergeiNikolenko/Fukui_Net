{
    "tokenizer_class": "SMILESTokenizer",
    "model_max_length": 512,
    "special_tokens": {
        "unk_token": "[UNK]",
        "pad_token": "[PAD]",
        "cls_token": "[CLS]",
        "sep_token": "[SEP]"
    },
    "clean_up_tokenization_spaces": true,
    "model_input_names": ["input_ids", "attention_mask"]
}
